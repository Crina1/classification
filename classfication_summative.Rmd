---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
telecom=read.csv(file.choose(),header=T)
attach(telecom)
library("skimr")
skim(telecom)
```


###Data Visualization
```{r}
DataExplorer::plot_bar(telecom, ncol = 2)
```
```{r}
DataExplorer::plot_histogram(telecom, ncol = 3)
```

```{r}
DataExplorer::plot_boxplot(telecom, by = "Churn", ncol = 3)
```

```{r}
DataExplorer::plot_bar(telecom, by = "Churn", ncol = 2)
```


```{r}
library("GGally")
ggpairs(telecom %>% select(SeniorCitizen, tenure, MonthlyCharges, TotalCharges),
        aes(color = Churn))
```



###Logistic Regression
```{r}
telecom_data <- telecom %>% 
  select(-PhoneService, -MultipleLines,-TotalCharges)

#after selecting the variables
tele.fit.lr=glm(as.factor(Churn) ~ ., binomial, telecom_data)
summary(tele.fit.lr)
```

```{r}
#res=step(tele.fit.lr,list(lower=~1,upper=formula(tele.fit.lr),scale=F,trace=F,direction="backward"))
#res$anova
```




```{r}
tele.pred.lr=predict(tele.fit.lr, telecom_data, type = "response")
ggplot(data.frame(x = tele.pred.lr), aes(x = x)) + geom_histogram()
```


```{r}
tele.conf.mat=table(`true Churn` = telecom_data$Churn=='Yes', `predict Churn` = tele.pred.lr > 0.5)
tele.conf.mat
tele.conf.mat/rowSums(tele.conf.mat)*100
```



####LDA
```{r}
tele_lda <- MASS::lda(Churn ~ ., telecom_data)
tele_lda
```
```{r}
tele_pred <- predict(tele_lda, na.omit(telecom_data))
#tele_pred
mat=table(truth = na.omit(telecom_data)$Churn, prediction = tele_pred$class)
mat
mat/rowSums(mat)*100
```

## MLR 3
```{r}
factor_name<-c("gender","Partner","Dependents","PhoneService","MultipleLines",
"InternetService","OnlineSecurity","OnlineBackup", "DeviceProtection","TechSupport",
"StreamingTV","StreamingMovies","Contract","PaperlessBilling","PaymentMethod")
idx <- which(names(telecom_data)   %in% factor_name)
for(i in idx ){
    telecom_data[,i]  <-  as.factor(telecom_data[,i])
}
task_tele <- TaskClassif$new(id = "telecom",
                               backend = na.omit(telecom_data),
                               target = "Churn")
task_tele
```

```{r}

library("mlr3learners")
library("mlr3proba")
```


##Logistic regression learner
```{r}
learner_lr=lrn("classif.log_reg")
learner_lr
learner_lr$train(task_tele)
pred_tele=learner_lr$predict(task_tele)
pred_tele
```

```{r}
pred_tele$score(msr("classif.acc"))
pred_tele$confusion
pred_tele$confusion/rowSums(pred_tele$confusion)*100
```

#3LDA learner
```{r}
learner_lda=lrn("classif.lda")

learner_lda$train(task_tele)

pred_lda_tele=learner_lda$predict(task_tele)

pred_lda_tele$score(msr("classif.acc"))
pred_lda_tele$confusion
pred_lda_tele$confusion/rowSums(pred_lda_tele$confusion)*100
```

```{r}
library("data.table")
library("mlr3verse")
```



###k-folds resampling
```{r}
set.seed(212) # set seed for reproducibility
tele_task=TaskClassif$new(id = "telecom",
                               backend = telecom_data, # <- NB: no na.omit() this time
                               target = "Churn",
                               positive = "Yes")

cv5 <- rsmp("cv", folds = 5)
cv5$instantiate(tele_task)
```


```{r}
lrn_baseline <- lrn("classif.featureless", predict_type = "prob")
lrn_cart <- lrn("classif.rpart", predict_type = "prob")
```

```{r}
tele_res_baseline <- resample(tele_task, lrn_baseline, cv5, store_models = TRUE)
tele_res_cart <- resample(tele_task, lrn_cart, cv5, store_models = TRUE)

# Look at accuracy
tele_res_baseline$aggregate()
tele_res_cart$aggregate()
```




```{r}
# results
tele_trees <- tele_res$resample_result(2)

# Then, let's look at the tree from first CV iteration, for example:
tele_tree1 <- trees$learners[[1]]

# This is a fitted rpart object, so we can look at the model within
tele_tree1_rpart <- tele_tree1$model

# If you look in the rpart package documentation, it tells us how to plot the
# tree that was fitted
plot(tele_tree1_rpart, compress = TRUE, margin = 0.1)
text(tele_tree1_rpart, use.n = TRUE, cex = 0.8)
```

```{r}
lrn_cart_cv <- lrn("classif.rpart", predict_type = "prob", xval = 10)

tele_res_cart_cv <- resample(tele_task, lrn_cart_cv, cv5, store_models = TRUE)
rpart::plotcp(tele_res_cart_cv$learners[[5]]$model)
```



```{r}
lrn_cart_cp <- lrn("classif.rpart", predict_type = "prob", cp = 0.016)
lrn_cart_cp
```


```{r}
# Create a pipeline which encodes and then fits an XGBoost model
lrn_xgboost <- lrn("classif.xgboost", predict_type = "prob")
pl_xgb <- po("encode") %>>%
  po(lrn_xgboost)

```



###### Dealing with missingness and factors
```{r}
pl_missing <- po("fixfactors") %>>%
  po("removeconstants") %>>%
  po("imputesample", affect_columns = selector_type(c("ordered", "factor"))) %>>%
  po("imputemean")

# Now try with a model that needs no missingness
lrn_log_reg <- lrn("classif.log_reg", predict_type = "prob")
pl_log_reg <- pl_missing %>>%
  po(lrn_log_reg)

# Now fit as normal ... we can just add it to our benchmark set
tele_res <- benchmark(data.table(
  task       = list(tele_task),
  learner    = list(lrn_baseline,
                    lrn_cart,
                    lrn_cart_cp,
                    pl_xgb,
                    pl_log_reg),
  resampling = list(cv5)
), store_models = TRUE)

tele_res$aggregate(list(msr("classif.ce"),
                   msr("classif.acc"),
                   msr("classif.fpr"),
                   msr("classif.fnr")))
```



```{r}
library("data.table")
library("mlr3verse")

set.seed(212) # set seed for reproducibility


# Define task
tele_task=TaskClassif$new(id = "telecom",
                               backend = telecom_data,
                               target = "Churn",
                               positive = "Yes")

# Cross validation resampling strategy
cv5 <- rsmp("cv", folds = 5)
cv5$instantiate(credit_task)

# Define a collection of base learners
lrn_baseline <- lrn("classif.featureless", predict_type = "prob")
lrn_cart     <- lrn("classif.rpart", predict_type = "prob")
lrn_cart_cp  <- lrn("classif.rpart", predict_type = "prob", cp = 0.016, id = "cartcp")
lrn_ranger   <- lrn("classif.ranger", predict_type = "prob")
lrn_xgboost  <- lrn("classif.xgboost", predict_type = "prob")
lrn_log_reg  <- lrn("classif.log_reg", predict_type = "prob")

# Define a super learner
lrnsp_log_reg <- lrn("classif.log_reg", predict_type = "prob", id = "super")

# Missingness imputation pipeline
pl_missing <- po("fixfactors") %>>%
  po("removeconstants") %>>%
  po("imputesample", affect_columns = selector_type(c("ordered", "factor"))) %>>%
  po("imputemean")

# Factors coding pipeline
pl_factor <- po("encode")

# Now define the full pipeline
spr_lrn <- gunion(list(
  # First group of learners requiring no modification to input
  gunion(list(
    po("learner_cv", lrn_baseline),
    po("learner_cv", lrn_cart),
    po("learner_cv", lrn_cart_cp)
  )),
  # Next group of learners requiring special treatment of missingness
  pl_missing %>>%
    gunion(list(
      po("learner_cv", lrn_ranger),
      po("learner_cv", lrn_log_reg),
      po("nop") # This passes through the original features adjusted for
                # missingness to the super learner
    )),
  # Last group needing factor encoding
  pl_factor %>>%
    po("learner_cv", lrn_xgboost)
)) %>>%
  po("featureunion") %>>%
  po(lrnsp_log_reg)

# This plot shows a graph of the learning pipeline
spr_lrn$plot()

# Finally fit the base learners and super learner and evaluate
res_spr <- resample(tele_task, spr_lrn, cv5, store_models = TRUE)
res_spr$aggregate(list(msr("classif.ce"),
                       msr("classif.acc"),
                       msr("classif.fpr"),
                       msr("classif.fnr")))
```




The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
